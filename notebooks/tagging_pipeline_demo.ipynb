{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging Pipeline - A DataFrames NLP API\n",
    "\n",
    "The `tagging_utils.tagging_utils` api pipeline is essentially a decorator framework built on top of `transformers.pipelines` from hugging face. The additional functionality added in `tagging_utils` allows the user to process a dataframe containing columns of text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:40:19.959133Z",
     "start_time": "2020-09-01T05:40:15.615124Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "from rsutils import tagging_utils as tu\n",
    "os.chdir('notebooks')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data 1 - Reddit Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:40:20.052121Z",
     "start_time": "2020-09-01T05:40:19.999124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>clicked</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>id</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>is_self</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>...</th>\n",
       "      <th>over_18</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ryzu99</td>\n",
       "      <td>&lt;praw.models.comment_forest.CommentForest obje...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.596393e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>i2gxgm</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/investing/comments/i2gxgm/portfolio_proposa...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi guys! I’ve been tinkering around with a the...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>investing</td>\n",
       "      <td>Portfolio Proposal (TechHeavy)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/i2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>djporter91</td>\n",
       "      <td>&lt;praw.models.comment_forest.CommentForest obje...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.596395e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>i2hpdk</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/investing/comments/i2hpdk/hedging_in_anothe...</td>\n",
       "      <td>1</td>\n",
       "      <td>I hold a long portfolio of monthly income stoc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>investing</td>\n",
       "      <td>Hedging in another brokerage account</td>\n",
       "      <td>0.56</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/i2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hhh888hhhh</td>\n",
       "      <td>&lt;praw.models.comment_forest.CommentForest obje...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.596396e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1596397045.0</td>\n",
       "      <td>i2hszf</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/investing/comments/i2hszf/2023_option_leaps...</td>\n",
       "      <td>9</td>\n",
       "      <td>\\r\\nIn anticipation of the new LEAPS to come o...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>investing</td>\n",
       "      <td>2023 option LEAPS will be introduced on Monday...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/i2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theonlyeasyday</td>\n",
       "      <td>&lt;praw.models.comment_forest.CommentForest obje...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.596396e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>i2hyab</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/investing/comments/i2hyab/why_dont_more_peo...</td>\n",
       "      <td>2</td>\n",
       "      <td>What am I missing with my thinking? What risks...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>investing</td>\n",
       "      <td>Why don't more people talk about fixed income?</td>\n",
       "      <td>0.58</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/i2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wesley_iles</td>\n",
       "      <td>&lt;praw.models.comment_forest.CommentForest obje...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.596397e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>i2ia4h</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/investing/comments/i2ia4h/curious_about_eve...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey investing!\\r\\n\\r\\nI know no one can predic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>investing</td>\n",
       "      <td>Curious about everyone’s educated guesses on t...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/i2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                           comments  clicked  \\\n",
       "0          ryzu99  <praw.models.comment_forest.CommentForest obje...    False   \n",
       "1      djporter91  <praw.models.comment_forest.CommentForest obje...    False   \n",
       "2      hhh888hhhh  <praw.models.comment_forest.CommentForest obje...    False   \n",
       "3  Theonlyeasyday  <praw.models.comment_forest.CommentForest obje...    False   \n",
       "4     wesley_iles  <praw.models.comment_forest.CommentForest obje...    False   \n",
       "\n",
       "    created_utc distinguished        edited      id  is_original_content  \\\n",
       "0  1.596393e+09           NaN         False  i2gxgm                False   \n",
       "1  1.596395e+09           NaN         False  i2hpdk                False   \n",
       "2  1.596396e+09           NaN  1596397045.0  i2hszf                False   \n",
       "3  1.596396e+09           NaN         False  i2hyab                False   \n",
       "4  1.596397e+09           NaN         False  i2ia4h                False   \n",
       "\n",
       "   is_self  link_flair_text  ...  over_18  \\\n",
       "0     True              NaN  ...    False   \n",
       "1     True              NaN  ...    False   \n",
       "2     True              NaN  ...    False   \n",
       "3     True              NaN  ...    False   \n",
       "4     True              NaN  ...    False   \n",
       "\n",
       "                                           permalink  score  \\\n",
       "0  /r/investing/comments/i2gxgm/portfolio_proposa...      0   \n",
       "1  /r/investing/comments/i2hpdk/hedging_in_anothe...      1   \n",
       "2  /r/investing/comments/i2hszf/2023_option_leaps...      9   \n",
       "3  /r/investing/comments/i2hyab/why_dont_more_peo...      2   \n",
       "4  /r/investing/comments/i2ia4h/curious_about_eve...      1   \n",
       "\n",
       "                                            selftext spoiler  stickied  \\\n",
       "0  Hi guys! I’ve been tinkering around with a the...   False     False   \n",
       "1  I hold a long portfolio of monthly income stoc...   False     False   \n",
       "2  \\r\\nIn anticipation of the new LEAPS to come o...   False     False   \n",
       "3  What am I missing with my thinking? What risks...   False     False   \n",
       "4  Hey investing!\\r\\n\\r\\nI know no one can predic...   False     False   \n",
       "\n",
       "   subreddit                                              title  upvote_ratio  \\\n",
       "0  investing                     Portfolio Proposal (TechHeavy)          0.50   \n",
       "1  investing               Hedging in another brokerage account          0.56   \n",
       "2  investing  2023 option LEAPS will be introduced on Monday...          0.71   \n",
       "3  investing     Why don't more people talk about fixed income?          0.58   \n",
       "4  investing  Curious about everyone’s educated guesses on t...          0.57   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.reddit.com/r/investing/comments/i2...  \n",
       "1  https://www.reddit.com/r/investing/comments/i2...  \n",
       "2  https://www.reddit.com/r/investing/comments/i2...  \n",
       "3  https://www.reddit.com/r/investing/comments/i2...  \n",
       "4  https://www.reddit.com/r/investing/comments/i2...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../submissions_stream.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:40:20.230118Z",
     "start_time": "2020-09-01T05:40:20.217124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103 entries, 0 to 102\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   author               103 non-null    object \n",
      " 1   comments             103 non-null    object \n",
      " 2   clicked              103 non-null    bool   \n",
      " 3   created_utc          103 non-null    float64\n",
      " 4   distinguished        2 non-null      object \n",
      " 5   edited               103 non-null    object \n",
      " 6   id                   103 non-null    object \n",
      " 7   is_original_content  103 non-null    bool   \n",
      " 8   is_self              103 non-null    bool   \n",
      " 9   link_flair_text      0 non-null      float64\n",
      " 10  locked               103 non-null    bool   \n",
      " 11  name                 103 non-null    object \n",
      " 12  num_comments         103 non-null    int64  \n",
      " 13  over_18              103 non-null    bool   \n",
      " 14  permalink            103 non-null    object \n",
      " 15  score                103 non-null    int64  \n",
      " 16  selftext             103 non-null    object \n",
      " 17  spoiler              103 non-null    bool   \n",
      " 18  stickied             103 non-null    bool   \n",
      " 19  subreddit            103 non-null    object \n",
      " 20  title                103 non-null    object \n",
      " 21  upvote_ratio         103 non-null    float64\n",
      " 22  url                  103 non-null    object \n",
      "dtypes: bool(7), float64(3), int64(2), object(11)\n",
      "memory usage: 13.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:40:20.888121Z",
     "start_time": "2020-09-01T05:40:20.385121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAASAElEQVR4nO3de4xcZ3nH8e+PXMiFoMRkbaxAuqSKAhGCJCyUKJSWmNBwSwJSKKi0Fgq4ErQCUQkcQED/qGQqlZuoAHOruZYQCHGhXIIpICRK2JAQAklqAs6FGHtJQQkXEQhP/5jjsrHX9uzaZ2bH7/cjrc4578yZ8zyJ/dvjd86cSVUhSWrHA8ZdgCRptAx+SWqMwS9JjTH4JakxBr8kNebwcRcwjBNPPLGmp6fHXYYkTZRrrrnmp1U1tfv4RAT/9PQ0s7Oz4y5DkiZKklsXGneqR5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGjMRn9w9ENPrPzu2Y2/b8MyxHVuS9sYzfklqTG/Bn+S0JNfN+7k7ySuSrEhyVZKt3fKEvmqQJO2pt+Cvqpur6oyqOgN4HPAr4ApgPbClqk4FtnTbkqQRGdVUzxrglqq6FbgQ2NSNbwIuGlENkiRGF/zPBz7Wra+qqu0A3XLlQjskWZdkNsns3NzciMqUpENf78Gf5EjgAuATi9mvqjZW1UxVzUxN7fE9ApKkJRrFGf/TgW9X1Y5ue0eS1QDdcucIapAkdUYR/C/gD9M8AJuBtd36WuDKEdQgSer0GvxJjgHOAz41b3gDcF6Srd1jG/qsQZJ0f71+creqfgU8ZLexuxhc5SNJGgM/uStJjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMb0GvxJjk9yeZKbktyY5OwkK5JclWRrtzyhzxokSffX9xn/24DPV9UjgccCNwLrgS1VdSqwpduWJI1Ib8Gf5MHAk4H3AVTVvVX1c+BCYFP3tE3ARX3VIEnaU59n/KcAc8AHklyb5L1JjgVWVdV2gG65cqGdk6xLMptkdm5urscyJaktfQb/4cBZwDur6kzglyxiWqeqNlbVTFXNTE1N9VWjJDWnz+C/A7ijqr7ZbV/O4BfBjiSrAbrlzh5rkCTtprfgr6qfALcnOa0bWgN8H9gMrO3G1gJX9lWDJGlPh/f8+n8PfCTJkcAPgRcx+GVzWZJLgNuAi3uuQZI0T6/BX1XXATMLPLSmz+NKkvbOT+5KUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxvX7ZepJtwD3AfcDvqmomyQrg48A0sA14XlX9rM86JEl/MIoz/qdU1RlVNdNtrwe2VNWpwJZuW5I0IuOY6rkQ2NStbwIuGkMNktSsvoO/gC8muSbJum5sVVVtB+iWKxfaMcm6JLNJZufm5nouU5La0escP3BOVd2ZZCVwVZKbht2xqjYCGwFmZmaqrwIlqTW9nvFX1Z3dcidwBfAEYEeS1QDdcmefNUiS7q+34E9ybJLjdq0DTwNuADYDa7unrQWu7KsGSdKe+pzqWQVckWTXcT5aVZ9P8i3gsiSXALcBF/dYgyRpN70Ff1X9EHjsAuN3AWv6Oq4kad/85K4kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqzFDBn+TRfRciSRqNYc/435Xk6iQvTXJ8nwVJkvo1VPBX1ZOAvwIeDswm+WiS83qtTJLUi6Hn+KtqK/A64NXAnwFvT3JTkuf2VZwk6eAbdo7/MUneAtwInAs8u6oe1a2/pcf6JEkH2bD36nkH8B7gNVX1612D3b32X9dLZZKkXgwb/M8Afl1V9wEkeQBwVFX9qqo+1Ft1kqSDbtg5/i8BR8/bPqYbkyRNmGGD/6iq+sWujW79mH5KkiT1adjg/2WSs3ZtJHkc8Ot9PF+StEwNO8f/CuATSe7stlcDf9lLRZKkXg0V/FX1rSSPBE4DAtxUVb/ttTJJUi8W89WLjwemu33OTEJVfbCXqiRJvRkq+JN8CPhj4Drgvm64AINfkibMsGf8M8DpVVWLPUCSw4BZ4MdV9awkK4CPM/jXwzbgeVX1s8W+riRpaYa9qucG4KFLPMbLGdzqYZf1wJaqOhXY0m1LkkZk2OA/Efh+ki8k2bzrZ387JXkY8EzgvfOGLwQ2deubgIsWUa8k6QANO9XzxiW+/luBVwHHzRtbVVXbAapqe5KVC+2YZB2wDuDkk09e4uElSbsb9n78X2UwH39Et/4t4Nv72ifJs4CdVXXNUgqrqo1VNVNVM1NTU0t5CUnSAoa9quclDM6+VzC4uuck4F3Amn3sdg5wQZJnAEcBD07yYWBHktXd2f5qYOeBNCBJWpxh5/hfxiDI74b//1KWBadodqmqS6vqYVU1DTwf+HJVvRDYDKztnrYWuHIJdUuSlmjY4P9NVd27ayPJ4Qyu41+KDcB5SbYC53XbkqQRGfbN3a8meQ1wdPdduy8F/mPYg1TVV4CvdOt3se8pIklSj4Y9418PzAHfBf4W+E8G378rSZoww96k7fcMvnrxPf2WI0nq27BX9fyIBeb0q+qUg16RJKlXi7lXzy5HARczuLRTkjRhhv0A113zfn5cVW8Fzu23NElSH4ad6jlr3uYDGPwL4Li9PF2StIwNO9XzL/PWf0d3O+WDXo0kqXfDXtXzlL4LkSSNxrBTPa/c1+NV9eaDU44kqW+Luarn8QzuswPwbOBrwO19FCVJ6s+wwX8icFZV3QOQ5I3AJ6rqxX0VJknqx7C3bDgZuHfe9r0MvjNXkjRhhj3j/xBwdZIrGHyC9znAB3urSpLUm2Gv6vmnJJ8D/rQbelFVXdtfWZKkvgw71QNwDHB3Vb0NuCPJI3qqSZLUo6GCP8kbgFcDl3ZDRwAf7qsoSVJ/hj3jfw5wAfBLgKq6E2/ZIEkTadjgv7eqiu7WzEmO7a8kSVKfhg3+y5K8Gzg+yUuAL+GXskjSRNrvVT1JAnwceCRwN3Aa8Pqqumo/+x3F4NO9D+yOc3lVvSHJiu71pulu9lZVPzuAHiRJi7Df4K+qSvLpqnocsM+w381vgHOr6hdJjgC+3l0S+lxgS1VtSLKewff5vnopxUuSFm/YqZ7/TvL4xbxwDfyi2zyi+yngQmBTN74JuGgxrytJOjDDBv9TGIT/LUmuT/LdJNfvb6ckhyW5DtgJXFVV3wRWVdV2gG65com1S5KWYJ9TPUlOrqrbgKcv5cWr6j7gjCTHA1ckefSw+yZZB6wDOPnkk5dyeEnSAvZ3xv9pgKq6FXhzVd06/2fYg1TVz4GvAOcDO5KsBuiWO/eyz8aqmqmqmampqWEPJUnaj/0Ff+atn7KYF04y1Z3pk+Ro4KnATQzu6b+2e9pa4MrFvK4k6cDs76qe2sv6MFYDm5IcxuAXzGVV9Zkk32DwuYBLgNuAixf5upKkA7C/4H9skrsZnPkf3a3TbVdVPXhvO1bV9cCZC4zfBaxZYr2SpAO0z+CvqsNGVYgkaTQWc1tmSdIhwOCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktSY/X3Z+pIleTjwQeChwO+BjVX1tiQrgI8D08A24HlV9bO+6hin6fWfHctxt2145liOK2ky9HnG/zvgH6rqUcATgZclOR1YD2ypqlOBLd22JGlEegv+qtpeVd/u1u8BbgROAi4ENnVP2wRc1FcNkqQ9jWSOP8k0cCbwTWBVVW2HwS8HYOVe9lmXZDbJ7Nzc3CjKlKQm9B78SR4EfBJ4RVXdPex+VbWxqmaqamZqaqq/AiWpMb0Gf5IjGIT+R6rqU93wjiSru8dXAzv7rEGSdH+9BX+SAO8DbqyqN897aDOwtltfC1zZVw2SpD31djkncA7w18B3k1zXjb0G2ABcluQS4Dbg4h5rkCTtprfgr6qvA9nLw2v6Oq4kad/85K4kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhrTW/AneX+SnUlumDe2IslVSbZ2yxP6Or4kaWF9nvH/G3D+bmPrgS1VdSqwpduWJI1Qb8FfVV8D/ne34QuBTd36JuCivo4vSVrYqOf4V1XVdoBuuXJvT0yyLslsktm5ubmRFShJh7pl++ZuVW2sqpmqmpmamhp3OZJ0yBh18O9IshqgW+4c8fElqXmjDv7NwNpufS1w5YiPL0nN6/Nyzo8B3wBOS3JHkkuADcB5SbYC53XbkqQROryvF66qF+zloTV9HVOStH/L9s1dSVI/DH5JaozBL0mNMfglqTEGvyQ1xuCXpMb0djmnxmd6/WfHctxtG545luNKWhzP+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xls26KAZ160iwNtFSIvhGb8kNcbgl6TGjGWqJ8n5wNuAw4D3VtWGcdQhHSint9pwqP1/HvkZf5LDgH8Fng6cDrwgyemjrkOSWjWOqZ4nAD+oqh9W1b3AvwMXjqEOSWrSOKZ6TgJun7d9B/Anuz8pyTpgXbf5iyQ3AycCP+29wtGwl4MobzqoLzf2foYxZM8T0cuQDqVeYMh+DvDP9h8tNDiO4M8CY7XHQNVGYOP9dkxmq2qmr8JGyV6Wr0OpH3tZvsbZzzimeu4AHj5v+2HAnWOoQ5KaNI7g/xZwapJHJDkSeD6weQx1SFKTRj7VU1W/S/J3wBcYXM75/qr63pC7b9z/UyaGvSxfh1I/9rJ8ja2fVO0xvS5JOoT5yV1JaozBL0mNmYjgT3J+kpuT/CDJ+nHXszdJ3p9kZ5Ib5o2tSHJVkq3d8oR5j13a9XRzkr+YN/64JN/tHnt7koUuge2zj4cn+a8kNyb5XpKXT2ovXQ1HJbk6yXe6fv5xkvvp6jgsybVJPjPJvSTZ1tVwXZLZSe6lq+P4JJcnuan7+3P2suynqpb1D4M3gG8BTgGOBL4DnD7uuvZS65OBs4Ab5o39M7C+W18PvKlbP73r5YHAI7oeD+seuxo4m8FnHj4HPH3EfawGzurWjwP+p6t34nrpagjwoG79COCbwBMntZ+ujlcCHwU+M6l/zroatgEn7jY2kb10dWwCXtytHwkcvxz7Gfl/mCX8hzwb+MK87UuBS8dd1z7qneb+wX8zsLpbXw3cvFAfDK5yOrt7zk3zxl8AvHvMPV0JnHeI9HIM8G0GnxafyH4YfPZlC3Aufwj+Se1lG3sG/6T28mDgR3QXzSznfiZhqmehWzycNKZalmJVVW0H6JYru/G99XVSt777+FgkmQbOZHCWPLG9dFMj1wE7gauqapL7eSvwKuD388YmtZcCvpjkmgxu0wKT28spwBzwgW4a7r1JjmUZ9jMJwT/ULR4m0N76Wjb9JnkQ8EngFVV1976eusDYsuqlqu6rqjMYnC0/Icmj9/H0ZdtPkmcBO6vqmmF3WWBsWfTSOaeqzmJwt96XJXnyPp673Hs5nMFU7zur6kzglwymdvZmbP1MQvBP+i0ediRZDdAtd3bje+vrjm599/GRSnIEg9D/SFV9qhueyF7mq6qfA18Bzmcy+zkHuCDJNgZ3tj03yYeZzF6oqju75U7gCgZ3753IXro67uj+NQlwOYNfBMuun0kI/km/xcNmYG23vpbBfPmu8ecneWCSRwCnAld3/xS8J8kTu3fy/2bePiPRHfd9wI1V9eZ5D01cLwBJppIc360fDTwVuIkJ7KeqLq2qh1XVNIO/C1+uqhdOYi9Jjk1y3K514GnADUxgLwBV9RPg9iSndUNrgO+zHPsZ9RsgS3zT5BkMriy5BXjtuOvZR50fA7YDv2XwW/sS4CEM3ojb2i1XzHv+a7uebmbeu/bADIO/ALcA72C3N4tG0MeTGPzT8nrguu7nGZPYS1fDY4Bru35uAF7fjU9kP/Nq+XP+8ObuxPXCYE78O93P93b93Z7EXubVcQYw2/1Z+zRwwnLsx1s2SFJjJmGqR5J0EBn8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTH/B/YmPu1tm25BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['selftext'].str.len().plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the very large texts had to be clipped due to limited number of tokens. In future I hope to add an ability to dynamically chunk the text to produce chunked results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:40:21.057122Z",
     "start_time": "2020-09-01T05:40:21.053122Z"
    }
   },
   "outputs": [],
   "source": [
    "data['selftext'] = data['selftext'].str.slice(0, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:40:23.246737Z",
     "start_time": "2020-09-01T05:40:21.211120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipe = tu.tagging_pipline('sentiment-analysis')  # ..., model, config, tokenizer, framework, **kwargs)\n",
    "sentiment_pipe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:40:26.954736Z",
     "start_time": "2020-09-01T05:40:23.439739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [{'label': 'POSITIVE', 'score': 0.950352609157...\n",
       "1      [{'label': 'NEGATIVE', 'score': 0.998081564903...\n",
       "2      [{'label': 'POSITIVE', 'score': 0.904251337051...\n",
       "3      [{'label': 'NEGATIVE', 'score': 0.973215699195...\n",
       "4      [{'label': 'POSITIVE', 'score': 0.995581626892...\n",
       "                             ...                        \n",
       "98     [{'label': 'NEGATIVE', 'score': 0.988896012306...\n",
       "99     [{'label': 'POSITIVE', 'score': 0.522240579128...\n",
       "100    [{'label': 'NEGATIVE', 'score': 0.975818634033...\n",
       "101    [{'label': 'NEGATIVE', 'score': 0.997027337551...\n",
       "102    [{'label': 'NEGATIVE', 'score': 0.884564101696...\n",
       "Name: title_sentiment, Length: 103, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_tags = sentiment_pipe(data, 'title')  # ..., tag_suffix: Optional[str], file: Optional[str], *args, **kwargs)\n",
    "sentiment_tags['title_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:40:53.592984Z",
     "start_time": "2020-09-01T05:40:27.295738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_sentiment</th>\n",
       "      <th>selftext_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portfolio Proposal (TechHeavy)</td>\n",
       "      <td>Hi guys! I’ve been tinkering around with a the...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.950352609157...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.995231330394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hedging in another brokerage account</td>\n",
       "      <td>I hold a long portfolio of monthly income stoc...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.998081564903...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.996959269046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023 option LEAPS will be introduced on Monday...</td>\n",
       "      <td>\\r\\nIn anticipation of the new LEAPS to come o...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.904251337051...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.998279809951...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why don't more people talk about fixed income?</td>\n",
       "      <td>What am I missing with my thinking? What risks...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.973215699195...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.996721267700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Curious about everyone’s educated guesses on t...</td>\n",
       "      <td>Hey investing!\\r\\n\\r\\nI know no one can predic...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.995581626892...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.982766568660...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kodak Loan Disclosure and Stock Surge Under SE...</td>\n",
       "      <td>https://www.wsj.com/articles/kodak-loan-disclo...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.988896012306...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.992655336856...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Conservative alternatives to high-yield savings</td>\n",
       "      <td>As much as I want to like the low interest rat...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.522240579128...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.988303661346...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Wkhs dd</td>\n",
       "      <td>\\r\\n- They are first and only ev company that ...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.975818634033...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.931227922439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>what happens to emerging market ETFs when a co...</td>\n",
       "      <td>The title pretty much says it all... my though...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.997027337551...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.998926699161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Looking forward, what would have to happen in ...</td>\n",
       "      <td>(I am someone with 40% of my net worth in inte...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.884564101696...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.985826373100...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                       Portfolio Proposal (TechHeavy)   \n",
       "1                 Hedging in another brokerage account   \n",
       "2    2023 option LEAPS will be introduced on Monday...   \n",
       "3       Why don't more people talk about fixed income?   \n",
       "4    Curious about everyone’s educated guesses on t...   \n",
       "..                                                 ...   \n",
       "98   Kodak Loan Disclosure and Stock Surge Under SE...   \n",
       "99     Conservative alternatives to high-yield savings   \n",
       "100                                            Wkhs dd   \n",
       "101  what happens to emerging market ETFs when a co...   \n",
       "102  Looking forward, what would have to happen in ...   \n",
       "\n",
       "                                              selftext  \\\n",
       "0    Hi guys! I’ve been tinkering around with a the...   \n",
       "1    I hold a long portfolio of monthly income stoc...   \n",
       "2    \\r\\nIn anticipation of the new LEAPS to come o...   \n",
       "3    What am I missing with my thinking? What risks...   \n",
       "4    Hey investing!\\r\\n\\r\\nI know no one can predic...   \n",
       "..                                                 ...   \n",
       "98   https://www.wsj.com/articles/kodak-loan-disclo...   \n",
       "99   As much as I want to like the low interest rat...   \n",
       "100  \\r\\n- They are first and only ev company that ...   \n",
       "101  The title pretty much says it all... my though...   \n",
       "102  (I am someone with 40% of my net worth in inte...   \n",
       "\n",
       "                                       title_sentiment  \\\n",
       "0    [{'label': 'POSITIVE', 'score': 0.950352609157...   \n",
       "1    [{'label': 'NEGATIVE', 'score': 0.998081564903...   \n",
       "2    [{'label': 'POSITIVE', 'score': 0.904251337051...   \n",
       "3    [{'label': 'NEGATIVE', 'score': 0.973215699195...   \n",
       "4    [{'label': 'POSITIVE', 'score': 0.995581626892...   \n",
       "..                                                 ...   \n",
       "98   [{'label': 'NEGATIVE', 'score': 0.988896012306...   \n",
       "99   [{'label': 'POSITIVE', 'score': 0.522240579128...   \n",
       "100  [{'label': 'NEGATIVE', 'score': 0.975818634033...   \n",
       "101  [{'label': 'NEGATIVE', 'score': 0.997027337551...   \n",
       "102  [{'label': 'NEGATIVE', 'score': 0.884564101696...   \n",
       "\n",
       "                                    selftext_sentiment  \n",
       "0    [{'label': 'NEGATIVE', 'score': 0.995231330394...  \n",
       "1    [{'label': 'NEGATIVE', 'score': 0.996959269046...  \n",
       "2    [{'label': 'NEGATIVE', 'score': 0.998279809951...  \n",
       "3    [{'label': 'NEGATIVE', 'score': 0.996721267700...  \n",
       "4    [{'label': 'POSITIVE', 'score': 0.982766568660...  \n",
       "..                                                 ...  \n",
       "98   [{'label': 'NEGATIVE', 'score': 0.992655336856...  \n",
       "99   [{'label': 'NEGATIVE', 'score': 0.988303661346...  \n",
       "100  [{'label': 'NEGATIVE', 'score': 0.931227922439...  \n",
       "101  [{'label': 'NEGATIVE', 'score': 0.998926699161...  \n",
       "102  [{'label': 'NEGATIVE', 'score': 0.985826373100...  \n",
       "\n",
       "[103 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "many_sentiment_tags = sentiment_pipe(data, ['title', 'selftext'])\n",
    "many_sentiment_tags[['title', 'selftext', 'title_sentiment', 'selftext_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:42:03.106264Z",
     "start_time": "2020-09-01T05:41:54.455414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipeline = tu.tagging_pipline('ner')\n",
    "ner_pipeline.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T19:56:54.730677Z",
     "start_time": "2020-09-02T19:56:54.727678Z"
    }
   },
   "source": [
    "## Sample Data 2 - Reddit Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:42:04.844700Z",
     "start_time": "2020-09-01T05:42:04.835692Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../comments_stream.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:43:16.547971Z",
     "start_time": "2020-09-01T05:42:06.833926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>body_nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beautiful country with a lot of history. My vi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your submission was removed because it is a sh...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow that reminds me of the time i wired $71,00...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You need to start writing reviews for them the...</td>\n",
       "      <td>[{'word': 'Omaha', 'score': 0.997726559638977,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>**Hi, welcome to /r/investing. Please note tha...</td>\n",
       "      <td>[{'word': 'Red', 'score': 0.6318739056587219, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>If anything Walmart will be the next Amazon. K...</td>\n",
       "      <td>[{'word': 'W', 'score': 0.9910761713981628, 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Kroger’s pickup experience is so shit-tastic, ...</td>\n",
       "      <td>[{'word': 'K', 'score': 0.9994198083877563, 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Nooo they're all going to laugh at you</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>The jewelry is basically purchased as a store ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>I’ve never had an issue, used instacart weekly...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0    Beautiful country with a lot of history. My vi...   \n",
       "1    Your submission was removed because it is a sh...   \n",
       "2    Wow that reminds me of the time i wired $71,00...   \n",
       "3    You need to start writing reviews for them the...   \n",
       "4    **Hi, welcome to /r/investing. Please note tha...   \n",
       "..                                                 ...   \n",
       "108  If anything Walmart will be the next Amazon. K...   \n",
       "109  Kroger’s pickup experience is so shit-tastic, ...   \n",
       "110             Nooo they're all going to laugh at you   \n",
       "111  The jewelry is basically purchased as a store ...   \n",
       "112  I’ve never had an issue, used instacart weekly...   \n",
       "\n",
       "                                           body_nertag  \n",
       "0                                                   []  \n",
       "1                                                   []  \n",
       "2                                                   []  \n",
       "3    [{'word': 'Omaha', 'score': 0.997726559638977,...  \n",
       "4    [{'word': 'Red', 'score': 0.6318739056587219, ...  \n",
       "..                                                 ...  \n",
       "108  [{'word': 'W', 'score': 0.9910761713981628, 'e...  \n",
       "109  [{'word': 'K', 'score': 0.9994198083877563, 'e...  \n",
       "110                                                 []  \n",
       "111                                                 []  \n",
       "112                                                 []  \n",
       "\n",
       "[113 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tags = ner_pipeline(data, 'body')\n",
    "ner_tags[['body', 'body_nertag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:43:18.642974Z",
     "start_time": "2020-09-01T05:43:17.104972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featextr_pipe = tu.tagging_pipline('feature-extraction')\n",
    "featextr_pipe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T05:44:21.589960Z",
     "start_time": "2020-09-01T05:44:10.117726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>body_extracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beautiful country with a lot of history. My vi...</td>\n",
       "      <td>[[[0.3953604996204376, 0.10346171259880066, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your submission was removed because it is a sh...</td>\n",
       "      <td>[[[0.5442933440208435, -0.03753986209630966, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow that reminds me of the time i wired $71,00...</td>\n",
       "      <td>[[[0.3470192849636078, 0.1690899133682251, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You need to start writing reviews for them the...</td>\n",
       "      <td>[[[0.42953211069107056, 0.08393619954586029, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>**Hi, welcome to /r/investing. Please note tha...</td>\n",
       "      <td>[[[0.45317259430885315, -0.03377668932080269, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>If anything Walmart will be the next Amazon. K...</td>\n",
       "      <td>[[[0.4139106273651123, 0.24311253428459167, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Kroger’s pickup experience is so shit-tastic, ...</td>\n",
       "      <td>[[[0.513343870639801, 0.08413420617580414, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Nooo they're all going to laugh at you</td>\n",
       "      <td>[[[0.2973708212375641, 0.1228756457567215, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>The jewelry is basically purchased as a store ...</td>\n",
       "      <td>[[[0.3005811274051666, 0.0022675860673189163, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>I’ve never had an issue, used instacart weekly...</td>\n",
       "      <td>[[[0.5258790254592896, 0.020975887775421143, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0    Beautiful country with a lot of history. My vi...   \n",
       "1    Your submission was removed because it is a sh...   \n",
       "2    Wow that reminds me of the time i wired $71,00...   \n",
       "3    You need to start writing reviews for them the...   \n",
       "4    **Hi, welcome to /r/investing. Please note tha...   \n",
       "..                                                 ...   \n",
       "108  If anything Walmart will be the next Amazon. K...   \n",
       "109  Kroger’s pickup experience is so shit-tastic, ...   \n",
       "110             Nooo they're all going to laugh at you   \n",
       "111  The jewelry is basically purchased as a store ...   \n",
       "112  I’ve never had an issue, used instacart weekly...   \n",
       "\n",
       "                                        body_extracted  \n",
       "0    [[[0.3953604996204376, 0.10346171259880066, -0...  \n",
       "1    [[[0.5442933440208435, -0.03753986209630966, -...  \n",
       "2    [[[0.3470192849636078, 0.1690899133682251, -0....  \n",
       "3    [[[0.42953211069107056, 0.08393619954586029, -...  \n",
       "4    [[[0.45317259430885315, -0.03377668932080269, ...  \n",
       "..                                                 ...  \n",
       "108  [[[0.4139106273651123, 0.24311253428459167, -0...  \n",
       "109  [[[0.513343870639801, 0.08413420617580414, 0.0...  \n",
       "110  [[[0.2973708212375641, 0.1228756457567215, -0....  \n",
       "111  [[[0.3005811274051666, 0.0022675860673189163, ...  \n",
       "112  [[[0.5258790254592896, 0.020975887775421143, -...  \n",
       "\n",
       "[113 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_tags = featextr_pipe(data, 'body')\n",
    "extraction_tags[['body', 'body_extracted']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Shown\n",
    "\n",
    "* question-answering\n",
    "* fill-mask\n",
    "* summarization\n",
    "* translation_en_to_fr\n",
    "* translation_en_to_de\n",
    "* translation_en_to_ro\n",
    "* text-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
